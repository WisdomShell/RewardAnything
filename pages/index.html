---
layout: default
title: "Home"
description: "RewardAnything: Generalizable Principle-Following Reward Models"
---

<!-- Hero Section -->
<section class="gradient-bg text-white py-20">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
        <div class="mb-8">
            <img src="{{ '/assets/images/hero-logo-placeholder.svg' | relative_url }}" 
                 alt="RewardAnything Hero Logo" 
                 class="h-24 w-auto mx-auto mb-6">
        </div>
        <h1 class="text-4xl md:text-6xl font-bold mb-6">
            RewardAnything
        </h1>
        <p class="text-xl md:text-2xl mb-8 text-blue-100 max-w-4xl mx-auto">
            Generalizable Principle-Following Reward Models
        </p>
        <p class="text-lg mb-10 text-blue-50 max-w-4xl mx-auto">
            Traditional reward models learn implicit preferences from chosen-rejected pairs, but human values are far more nuanced than any single distribution. Just as LLMs follow instructions, reward models should follow explicitly specified principles‚Äîenabling dynamic adaptation to diverse evaluation criteria without costly retraining.
        </p>
        
        <!-- CTA Buttons -->
        <div class="flex flex-col sm:flex-row gap-4 justify-center items-center">
            <a href="#quickstart" 
               class="bg-white text-blue-600 px-8 py-3 rounded-lg font-semibold hover:bg-blue-50 transition-all transform hover:scale-105">
                Get Started
            </a>
            <a href="{{ site.paper_url }}" 
               class="border-2 border-white text-white px-8 py-3 rounded-lg font-semibold hover:bg-white hover:text-blue-600 transition-all">
                Read Paper
            </a>
        </div>

        <!-- Badges -->
        <div class="flex flex-wrap justify-center gap-4 mt-10">
            <a href="{{ site.pypi_url }}" class="badge bg-blue-100 text-blue-800 hover:bg-blue-200 transition-colors">
                <svg class="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
                    <path d="M3 4a1 1 0 011-1h12a1 1 0 011 1v2a1 1 0 01-1 1H4a1 1 0 01-1-1V4zM3 10a1 1 0 011-1h6a1 1 0 011 1v6a1 1 0 01-1 1H4a1 1 0 01-1-1v-6zM14 9a1 1 0 00-1 1v6a1 1 0 001 1h2a1 1 0 001-1v-6a1 1 0 00-1-1h-2z"/>
                </svg>
                PyPI Package
            </a>
            <a href="{{ site.huggingface_url }}" class="badge bg-yellow-100 text-yellow-800 hover:bg-yellow-200 transition-colors">
                ü§ó Model Weights
            </a>
            <a href="{{ site.paper_url }}" class="badge bg-purple-100 text-purple-800 hover:bg-purple-200 transition-colors">
                üìÑ arXiv Paper
            </a>
        </div>
    </div>
</section>

<!-- Authors Section -->
<section class="py-12 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
        <div class="text-sm text-gray-600 mb-4">
            <div class="flex flex-wrap justify-center gap-x-6 gap-y-2">
                <span>Zhuohao Yu<sup>1,¬ß</sup></span>
                <span>Jiali Zeng<sup>2</sup></span>
                <span>Weizheng Gu<sup>1</sup></span>
                <span>Yidong Wang<sup>1</sup></span>
                <span>Jindong Wang<sup>3</sup></span>
                <span>Fandong Meng<sup>2</sup></span>
                <span>Jie Zhou<sup>2</sup></span>
                <span>Yue Zhang<sup>4</sup></span>
                <span>Shikun Zhang<sup>1</sup></span>
                <span>Wei Ye<sup>1,‚Ä†</sup></span>
            </div>
        </div>
        <div class="text-xs text-gray-500">
            <div class="mb-2">
                <sup>1</sup>Peking University &emsp;
                <sup>2</sup>WeChat AI &emsp;
                <sup>3</sup>William & Mary &emsp;
                <sup>4</sup>Westlake University
            </div>
            <p><sup>¬ß</sup>Work done during internship at WeChat AI &emsp; <sup>‚Ä†</sup>Corresponding author</p>
        </div>
    </div>
</section>

<!-- Problem & Solution Overview -->
<section class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">The Problem with Current Reward Models</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                Traditional reward models learn implicit preferences from fixed datasets, making them rigid and unable to adapt to diverse real-world needs.
            </p>
        </div>

        <!-- Research Figure Container -->
        <div class="paper-figure-container mb-16">
            <div class="max-w-5xl mx-auto">
                <img src="{{ '/assets/images/figure_1_placeholder.jpg' | relative_url }}" 
                     alt="Figure 1: Current post-training optimization paradigm vs RewardAnything approach"
                     class="w-full h-auto rounded-lg shadow-sm">
                <p class="text-sm text-gray-600 text-center mt-4 italic">
                    <strong>Figure 1:</strong> Current post-training optimization requires costly retraining for different preferences. 
                    RewardAnything directly follows natural language principles without retraining.
                </p>
            </div>
        </div>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-12">
            <!-- Current Limitations -->
            <div class="bg-red-50 p-8 rounded-xl">
                <div class="text-red-600 text-2xl mb-4">‚ö†Ô∏è</div>
                <h3 class="text-xl font-bold text-red-900 mb-4">Current Limitations</h3>
                <ul class="space-y-3 text-red-800">
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Limited Adaptability:</strong> Need to retrain for different preference criteria</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Implicit Learning:</strong> Learn biases from spurious correlations in data</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Poor Interpretability:</strong> Cannot explain why certain responses are preferred</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Costly Process:</strong> Expensive data collection and retraining cycles</span>
                    </li>
                </ul>
            </div>

            <!-- Our Solution -->
            <div class="bg-green-50 p-8 rounded-xl">
                <div class="text-green-600 text-2xl mb-4">‚úÖ</div>
                <h3 class="text-xl font-bold text-green-900 mb-4">RewardAnything Solution</h3>
                <ul class="space-y-3 text-green-800">
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Dynamic Adaptation:</strong> Follow explicit natural language principles at inference</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Principle-Grounded:</strong> Transparent, interpretable evaluation criteria</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Zero Retraining:</strong> Adapt to new preferences without additional training</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Bias Mitigation:</strong> Explicit principles reduce spurious correlations</span>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</section>

<!-- Quick Start -->
<section id="quickstart" class="py-20 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">Quick Start</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                Get started with RewardAnything in just a few lines of code
            </p>
        </div>

        <div class="max-w-4xl mx-auto">
            <!-- Installation -->
            <div class="bg-gray-50 p-6 rounded-xl mb-8">
                <h3 class="text-lg font-semibold text-gray-900 mb-4">üöÄ Installation</h3>
                <pre class="bg-gray-900 text-green-400 p-4 rounded-lg overflow-x-auto"><code>pip install rewardanything</code></pre>
            </div>

            <!-- Basic Usage -->
            <div class="bg-gray-50 p-6 rounded-xl mb-8">
                <h3 class="text-lg font-semibold text-gray-900 mb-4">üí° Basic Usage</h3>
                <pre class="bg-gray-900 text-gray-300 p-4 rounded-lg overflow-x-auto text-sm"><code>from rewardanything import RewardModel

# Load the model
reward_model = RewardModel.from_pretrained("zhuohaoyu/RewardAnything-8B-v1")

# Define your principle
principle = "Favor responses that are helpful, accurate, and concise"

# Evaluate responses
prompt = "What is machine learning?"
responses = [
    "Machine learning is a subset of AI...",
    "ML uses algorithms to find patterns in data..."
]

scores = reward_model.evaluate(
    principle=principle,
    prompt=prompt, 
    responses=responses
)

print(scores)  # {'response_1': 4.2, 'response_2': 3.8}</code></pre>
            </div>

            <!-- Advanced Example -->
            <div class="bg-blue-50 p-6 rounded-xl">
                <h3 class="text-lg font-semibold text-blue-900 mb-4">üî¨ Advanced: Custom Principles</h3>
                <pre class="bg-gray-900 text-gray-300 p-4 rounded-lg overflow-x-auto text-sm"><code># Define complex, multi-faceted principles
safety_principle = """
Safety comes first but avoid overly sensitive rejections. 
Value warmth, appropriate humor, and genuine helpfulness.
Content and tone are more important than presentation style.
"""

# Use for RLHF training
from rewardanything.training import GRPO

trainer = GRPO(reward_model=reward_model)
aligned_model = trainer.train(
    policy_model="qwen/Qwen-8B", 
    principle=safety_principle,
    prompts=training_prompts
)</code></pre>
            </div>
        </div>
    </div>
</section>

<!-- Performance Results -->
<section class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">State-of-the-Art Performance</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                RewardAnything achieves superior results on both traditional and principle-following benchmarks
            </p>
        </div>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-12">
            <!-- RM-Bench Results -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <h3 class="text-xl font-bold text-gray-900 mb-6">RM-Bench Results</h3>
                <div class="space-y-4">
                    <div class="flex justify-between items-center">
                        <span class="text-gray-700">Overall Accuracy</span>
                        <span class="text-2xl font-bold text-blue-600">89.2%</span>
                    </div>
                    <div class="w-full bg-gray-200 rounded-full h-2">
                        <div class="bg-blue-600 h-2 rounded-full" style="width: 89.2%"></div>
                    </div>
                    <div class="grid grid-cols-2 gap-4 text-sm">
                        <div>
                            <span class="text-gray-600">Math:</span>
                            <span class="font-semibold ml-1">89.1%</span>
                        </div>
                        <div>
                            <span class="text-gray-600">Safety:</span>
                            <span class="font-semibold ml-1">100%</span>
                        </div>
                    </div>
                    <p class="text-sm text-gray-600 mt-4">
                        üèÜ <strong>State-of-the-art</strong> performance achieved by simply specifying evaluation principles
                    </p>
                </div>
            </div>

            <!-- RABench Results -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <h3 class="text-xl font-bold text-gray-900 mb-6">RABench (Our Benchmark)</h3>
                <div class="space-y-4">
                    <div class="flex justify-between items-center">
                        <span class="text-gray-700">Principle Following</span>
                        <span class="text-2xl font-bold text-green-600">80.5%</span>
                    </div>
                    <div class="w-full bg-gray-200 rounded-full h-2">
                        <div class="bg-green-600 h-2 rounded-full" style="width: 80.5%"></div>
                    </div>
                    <div class="grid grid-cols-2 gap-4 text-sm">
                        <div>
                            <span class="text-gray-600">Kendall's œÑ:</span>
                            <span class="font-semibold ml-1">62.59</span>
                        </div>
                        <div>
                            <span class="text-gray-600">NDCG:</span>
                            <span class="font-semibold ml-1">97.24</span>
                        </div>
                    </div>
                    <p class="text-sm text-gray-600 mt-4">
                        üéØ <strong>Competitive with GPT-4o</strong> on novel principle adaptation without retraining
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Methodology -->
<section class="py-20 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">Methodology</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                Our approach combines Group Relative Policy Optimization (GRPO) with principle-guided training
            </p>
        </div>

        <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
            <!-- GRPO Training -->
            <div class="text-center">
                <div class="bg-blue-100 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                    <svg class="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                        <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                    </svg>
                </div>
                <h3 class="text-lg font-semibold text-gray-900 mb-3">Group Relative Policy Optimization</h3>
                <p class="text-gray-600">
                    Advanced RL training that learns from relative rankings rather than absolute scores, 
                    enabling better generalization across principles.
                </p>
            </div>

            <!-- Principle Categories -->
            <div class="text-center">
                <div class="bg-green-100 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                    <svg class="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
                        <path d="M9 2a1 1 0 000 2h2a1 1 0 100-2H9z"/>
                        <path fill-rule="evenodd" d="M4 5a2 2 0 012-2 3 3 0 003 3h2a3 3 0 003-3 2 2 0 012 2v6a2 2 0 01-2 2H6a2 2 0 01-2-2V5zm3 2V6a1 1 0 011-1h.01a1 1 0 011 1v1a2 2 0 11-2 0zm3 0V6a1 1 0 011-1h.01a1 1 0 011 1v1a2 2 0 11-2 0z" clip-rule="evenodd"/>
                    </svg>
                </div>
                <h3 class="text-lg font-semibold text-gray-900 mb-3">Structured Principle Framework</h3>
                <p class="text-gray-600">
                    200+ curated principles across Logic, Content, Structure, Style, and Tone categories 
                    for comprehensive evaluation criteria.
                </p>
            </div>

            <!-- RABench -->
            <div class="text-center">
                <div class="bg-purple-100 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                    <svg class="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
                        <path d="M2 10a8 8 0 018-8v8h8a8 8 0 11-16 0z"/>
                        <path d="M12 2.252A8.014 8.014 0 0117.748 8H12V2.252z"/>
                    </svg>
                </div>
                <h3 class="text-lg font-semibold text-gray-900 mb-3">RABench Evaluation</h3>
                <p class="text-gray-600">
                    Comprehensive benchmark with 1,002 validated rankings to measure 
                    principle-following capabilities across diverse domains.
                </p>
            </div>
        </div>

        <!-- Technical Details -->
        <div class="mt-16 bg-gray-50 p-8 rounded-xl">
            <h3 class="text-xl font-bold text-gray-900 mb-6">Key Technical Innovations</h3>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="space-y-4">
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Listwise Training</h4>
                            <p class="text-gray-600">More efficient than pairwise approaches, enabling fine-grained ranking</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Inference-Time Reasoning</h4>
                            <p class="text-gray-600">Explicit reasoning process for transparent decision making</p>
                        </div>
                    </div>
                </div>
                <div class="space-y-4">
                    <div class="flex items-start">
                        <div class="bg-green-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-green-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Multi-LLM Consensus</h4>
                            <p class="text-gray-600">Ground truth from 4 state-of-the-art LLMs with algorithmic consensus</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-green-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-green-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Human Verification</h4>
                            <p class="text-gray-600">89% agreement rate with Œ∫=0.57 for reliable evaluation standards</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Documentation -->
<section id="documentation" class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">Documentation & Resources</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                Everything you need to understand and use RewardAnything for your research and applications
            </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6">
            <a href="{{ site.paper_url }}" class="block bg-blue-50 p-6 rounded-xl hover:bg-blue-100 transition-colors">
                <div class="text-2xl mb-3">üìÑ</div>
                <h3 class="font-semibold text-blue-900 mb-2">Research Paper</h3>
                <p class="text-sm text-blue-700">Complete methodology, experiments, and theoretical foundations</p>
            </a>

            <a href="#" class="block bg-green-50 p-6 rounded-xl hover:bg-green-100 transition-colors">
                <div class="text-2xl mb-3">üöÄ</div>
                <h3 class="font-semibold text-green-900 mb-2">API Documentation</h3>
                <p class="text-sm text-green-700">Comprehensive guide to using RewardAnything in your code</p>
            </a>

            <a href="#" class="block bg-purple-50 p-6 rounded-xl hover:bg-purple-100 transition-colors">
                <div class="text-2xl mb-3">üìä</div>
                <h3 class="font-semibold text-purple-900 mb-2">RABench Dataset</h3>
                <p class="text-sm text-purple-700">Benchmark dataset for evaluating principle-following capabilities</p>
            </a>

            <a href="{{ site.huggingface_url }}" class="block bg-orange-50 p-6 rounded-xl hover:bg-orange-100 transition-colors">
                <div class="text-2xl mb-3">ü§ó</div>
                <h3 class="font-semibold text-orange-900 mb-2">Model Weights</h3>
                <p class="text-sm text-orange-700">Pre-trained models ready for inference and fine-tuning</p>
            </a>
        </div>
    </div>
</section>

<!-- Citation -->
<section class="py-20 bg-gray-900 text-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-12">
            <h2 class="text-3xl md:text-4xl font-bold mb-4">Citation</h2>
            <p class="text-xl text-gray-300 max-w-3xl mx-auto">
                If you use RewardAnything in your research, please cite our paper
            </p>
        </div>

        <div class="max-w-4xl mx-auto">
            <div class="bg-gray-800 p-6 rounded-xl">
                <pre class="text-gray-300 font-mono text-sm overflow-x-auto"><code>@article{yu2024rewardanything,
  title={RewardAnything: Generalizable Principle-Following Reward Models},
  author={Yu, Zhuohao and Zeng, Jiali and Gu, Weizheng and Wang, Yidong and 
          Wang, Jindong and Meng, Fandong and Zhou, Jie and Zhang, Yue and 
          Zhang, Shikun and Ye, Wei},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2025}
}</code></pre>
            </div>
        </div>
    </div>
</section>

<style>
/* Special container for paper figures with neutral background */
.paper-figure-container {
    background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
    padding: 2rem;
    border-radius: 1rem;
    border: 1px solid #e2e8f0;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05);
}

.paper-figure-container img {
    background: white;
    padding: 1rem;
    border-radius: 0.5rem;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}
</style> 