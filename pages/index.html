---
layout: default
title: "Home"
description: "RewardAnything: Generalizable Principle-Following Reward Models"
---

<!-- Hero Section -->
<section class="gradient-bg text-slate-700 py-12">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
        <div class="mb-6">
            <!-- Use your regular logo - it will look perfect on this lighter background -->
            <img src="{{ '/assets/images/rewardanything-logo-horizontal.png' | relative_url }}" 
                 alt="RewardAnything" 
                 class="h-14 md:h-18 w-auto mx-auto mb-4">
        </div>
        
        <p class="text-2xl md:text-3xl mb-10 text-slate-700 max-w-4xl mx-auto font-bold">
            Generalizable Principle-Following Reward Models
        </p>
        
        <!-- Simplified TLDR with cleaner formatting -->
        <div class="text-base md:text-lg mb-10 text-slate-600 max-w-7xl mx-auto leading-relaxed">
            <p class="mb-4">
                Traditional reward models learn <span class="font-semibold text-slate-800">implicit preferences</span> behind chosen-rejected pairs,<br>
                but human values are <span class="italic text-slate-700">far more nuanced</span> than any single distribution.
            </p>
            <p>
                <span class="font-semibold text-slate-800">Just as LLMs follow instructions</span>, reward models should follow<br>
                <span class="font-semibold text-blue-700">explicitly specified principles</span>‚Äîenabling inference-time adaptation to diverse evaluation criteria<br>
                <span class="font-medium text-slate-700">without costly retraining</span>.
            </p>
        </div>
        
        <!-- Updated CTA Buttons -->
        <div class="flex flex-col sm:flex-row gap-3 justify-center items-center mb-10">
            <a href="{{ site.paper_url | default: '#' }}" 
               class="inline-flex items-center bg-white text-slate-700 px-6 py-2.5 rounded-lg font-semibold hover:bg-slate-50 transition-all transform hover:scale-105 shadow-lg border border-slate-200">
                üìÑ <span class="ml-2">Paper</span>
            </a>
            <a href="{{ site.huggingface_url | default: '#' }}" 
               class="inline-flex items-center bg-gradient-to-r from-yellow-400 to-orange-500 text-white px-6 py-2.5 rounded-lg font-semibold hover:from-yellow-500 hover:to-orange-600 transition-all transform hover:scale-105 shadow-lg">
                ü§ó <span class="ml-2">Model Weights</span>
            </a>
            <a href="#quickstart" 
               class="inline-flex items-center bg-gradient-to-r from-emerald-500 to-teal-600 text-white px-6 py-2.5 rounded-lg font-semibold hover:from-emerald-600 hover:to-teal-700 transition-all transform hover:scale-105 shadow-lg">
                üíª <span class="ml-2">Get Started</span>
            </a>
        </div>
    </div>
</section>

<!-- Authors Section -->
<section class="py-10 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
        <div class="text-base md:text-lg text-gray-700 mb-6">
            <div class="space-y-3">
                <!-- First line of authors (5 authors) -->
            <div class="flex flex-wrap justify-center gap-x-6 gap-y-2">
                <span>Zhuohao Yu<sup>1,¬ß</sup></span>
                <span>Jiali Zeng<sup>2</sup></span>
                <span>Weizheng Gu<sup>1</sup></span>
                <span>Yidong Wang<sup>1</sup></span>
                <span>Jindong Wang<sup>3</sup></span>
                </div>
                <!-- Second line of authors (5 authors) -->
                <div class="flex flex-wrap justify-center gap-x-6 gap-y-2">
                <span>Fandong Meng<sup>2</sup></span>
                <span>Jie Zhou<sup>2</sup></span>
                <span>Yue Zhang<sup>4</sup></span>
                <span>Shikun Zhang<sup>1</sup></span>
                <span>Wei Ye<sup>1,‚Ä†</sup></span>
            </div>
        </div>
        </div>
        <div class="text-base md:text-lg text-gray-600">
            <div class="mb-4 font-bold">
                <sup>1</sup>Peking University &emsp;
                <sup>2</sup>WeChat AI &emsp;
                <sup>3</sup>William & Mary &emsp;
                <sup>4</sup>Westlake University
            </div>
            <p class="text-sm md:text-base text-gray-500">
                <sup>¬ß</sup>Work done during internship at WeChat AI &emsp; <sup>‚Ä†</sup>Corresponding author
            </p>
        </div>
    </div>
</section>

<!-- Problem Demonstration with Real Cases -->
<section class="py-20 bg-gradient-to-br from-red-50 to-orange-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">The Problem: Static, Implicit Reward Learning</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                Current reward models learn <span class="font-semibold text-red-600">implicit preferences</span> from chosen-rejected pairs, 
                leading to <span class="font-semibold text-red-600">spurious correlations</span> and <span class="font-semibold text-red-600">limited adaptability</span>.
            </p>
        </div>

        <!-- Problem Illustration with Real Cases -->
        <div class="grid lg:grid-cols-2 gap-12 mb-16">
            <!-- Case 1: Length Bias -->
            <div class="bg-white rounded-2xl p-8 shadow-lg border border-red-100">
                <div class="flex items-center mb-6">
                    <div class="bg-red-100 p-3 rounded-lg mr-4">
                        <svg class="w-6 h-6 text-red-600" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z" clip-rule="evenodd"/>
                        </svg>
                    </div>
                    <div>
                        <h3 class="text-xl font-bold text-gray-900">Issue #1: Length = Quality Bias</h3>
                        <p class="text-sm text-gray-600">Models learn "longer responses are better" instead of "accurate responses are better"</p>
                    </div>
                </div>
                
                <div class="space-y-4">
                    <div class="bg-blue-50 p-4 rounded-lg border-l-4 border-blue-400">
                        <div class="text-sm font-semibold text-blue-900 mb-2">üôã Prompt:</div>
                        <p class="text-blue-800 text-sm">"What are some species of bears that are now extinct?"</p>
                    </div>
                    
                    <div class="grid md:grid-cols-2 gap-4">
                        <div class="bg-green-50 p-4 rounded-lg border border-green-200">
                            <div class="flex items-center mb-2">
                                <span class="text-green-600 font-semibold text-sm mr-2">‚úÖ Chosen (Long + Correct)</span>
                            </div>
                            <p class="text-green-800 text-xs leading-relaxed">
                                "Several species of bears have become extinct... <strong>Cave Bear (Ursus spelaeus)</strong>: One of the best-known extinct bear species... <strong>Short-faced Bear (Arctodus simus)</strong>: Once the largest..."
                            </p>
                            <div class="mt-2 text-xs text-green-600">
                                ‚úì Accurate facts ‚úì Detailed explanations
                            </div>
                        </div>
                        
                        <div class="bg-red-50 p-4 rounded-lg border border-red-200">
                            <div class="flex items-center mb-2">
                                <span class="text-red-600 font-semibold text-sm mr-2">‚ùå Rejected (Short + Wrong)</span>
                            </div>
                            <p class="text-red-800 text-xs leading-relaxed">
                                "Three species of bears that are now extinct are the <strong>woolly mammoth</strong>, the <strong>woolly rhinoceros</strong>, and the <strong>thylacine</strong>."
                            </p>
                            <div class="mt-2 text-xs text-red-600">
                                ‚ùå Factually incorrect ‚ùå None are bears
                            </div>
                        </div>
                    </div>
                    
                    <div class="bg-yellow-50 p-4 rounded-lg border border-yellow-200">
                        <div class="text-sm font-semibold text-yellow-800 mb-1">‚ö†Ô∏è What Current RMs Learn:</div>
                        <p class="text-yellow-700 text-sm">"Longer responses are better" ‚Äî but what if the user wanted a brief answer?</p>
                    </div>
                </div>
            </div>

            <!-- Case 2: Format Over Content -->
            <div class="bg-white rounded-2xl p-8 shadow-lg border border-red-100">
                <div class="flex items-center mb-6">
                    <div class="bg-red-100 p-3 rounded-lg mr-4">
                        <svg class="w-6 h-6 text-red-600" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z" clip-rule="evenodd"/>
                        </svg>
                    </div>
                    <div>
                        <h3 class="text-xl font-bold text-gray-900">Issue #2: Format Over Substance</h3>
                        <p class="text-sm text-gray-600">Models prioritize structure and completeness over actual content quality</p>
                    </div>
                </div>
                
                <div class="space-y-4">
                    <div class="bg-blue-50 p-4 rounded-lg border-l-4 border-blue-400">
                        <div class="text-sm font-semibold text-blue-900 mb-2">üôã Prompt:</div>
                        <p class="text-blue-800 text-sm">"What are some good browser alternatives to Chrome?"</p>
                    </div>
                    
                    <div class="grid md:grid-cols-2 gap-4">
                        <div class="bg-green-50 p-4 rounded-lg border border-green-200">
                            <div class="flex items-center mb-2">
                                <span class="text-green-600 font-semibold text-sm mr-2">‚úÖ Chosen (Well-Structured)</span>
                            </div>
                            <p class="text-green-800 text-xs leading-relaxed">
                                "There are several good browser alternatives... <strong>1. Mozilla Firefox:</strong> Strong privacy features, Open-source, Customizable... <strong>2. Microsoft Edge:</strong> Built on Chromium..."
                            </p>
                            <div class="mt-2 text-xs text-green-600">
                                ‚úì Clear structure ‚úì Complete response
                            </div>
                        </div>
                        
                        <div class="bg-red-50 p-4 rounded-lg border border-red-200">
                            <div class="flex items-center mb-2">
                                <span class="text-red-600 font-semibold text-sm mr-2">‚ùå Rejected (Incomplete)</span>
                            </div>
                            <p class="text-red-800 text-xs leading-relaxed">
                                "Some good browser alternatives... Firefox offers... Vivaldi is a fast and customizable browser... Opera offers a range of features including a built-in ad blocker, secure password manager,"
                            </p>
                            <div class="mt-2 text-xs text-red-600">
                                ‚ùå Cuts off mid-sentence ‚ùå Incomplete
                            </div>
                        </div>
                    </div>
                    
                    <div class="bg-yellow-50 p-4 rounded-lg border border-yellow-200">
                        <div class="text-sm font-semibold text-yellow-800 mb-1">‚ö†Ô∏è What Current RMs Learn:</div>
                        <p class="text-yellow-700 text-sm">"Complete, structured responses are better" ‚Äî but what about different user needs?</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- The Core Problems -->
        <div class="bg-white rounded-2xl p-8 shadow-lg border border-gray-200">
            <h3 class="text-2xl font-bold text-gray-900 mb-6 text-center">Why Current Reward Models Fail</h3>
            
            <div class="grid md:grid-cols-2 lg:grid-cols-4 gap-6">
                <div class="text-center">
                    <div class="bg-red-100 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <svg class="w-8 h-8 text-red-600" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M4 2a1 1 0 011 1v2.101a7.002 7.002 0 0111.601 2.566 1 1 0 11-1.885.666A5.002 5.002 0 005.999 7H9a1 1 0 010 2H4a1 1 0 01-1-1V3a1 1 0 011-1zm.008 9.057a1 1 0 011.276.61A5.002 5.002 0 0014.001 13H11a1 1 0 110-2h5a1 1 0 011 1v5a1 1 0 11-2 0v-2.101a7.002 7.002 0 01-11.601-2.566 1 1 0 01.61-1.276z" clip-rule="evenodd"/>
                        </svg>
                    </div>
                    <h4 class="font-semibold text-gray-900 mb-2">Static Preferences</h4>
                    <p class="text-sm text-gray-600">Same criteria for all contexts ‚Äî customer service vs academic research</p>
                </div>
                
                <div class="text-center">
                    <div class="bg-red-100 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <svg class="w-8 h-8 text-red-600" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M3 4a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm0 4a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm0 4a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"/>
                        </svg>
                    </div>
                    <h4 class="font-semibold text-gray-900 mb-2">Spurious Correlations</h4>
                    <p class="text-sm text-gray-600">Learn "length = quality" instead of actual quality metrics</p>
                </div>
                
                <div class="text-center">
                    <div class="bg-red-100 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <svg class="w-8 h-8 text-red-600" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M18 8A6 6 0 006 8v2.5A3.5 3.5 0 009.5 14h1A3.5 3.5 0 0014 10.5V8a6 6 0 00-6-6z" clip-rule="evenodd"/>
                        </svg>
                    </div>
                    <h4 class="font-semibold text-gray-900 mb-2">Implicit Learning</h4>
                    <p class="text-sm text-gray-600">No explicit rationale ‚Äî only outcome supervision from chosen-rejected pairs</p>
                </div>
                
                <div class="text-center">
                    <div class="bg-red-100 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <svg class="w-8 h-8 text-red-600" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z" clip-rule="evenodd"/>
                        </svg>
                    </div>
                    <h4 class="font-semibold text-gray-900 mb-2">Costly Adaptation</h4>
                    <p class="text-sm text-gray-600">New criteria require expensive data collection and model retraining</p>
                </div>
            </div>
        </div>

        <!-- The Paradigm Shift -->
        <div class="mt-12 text-center">
            <div class="bg-gradient-to-r from-blue-600 to-purple-600 text-white p-8 rounded-2xl shadow-lg">
                <h3 class="text-2xl font-bold mb-4">The Solution: Principle-Following Reward Models</h3>
                <p class="text-lg mb-6 max-w-4xl mx-auto">
                    Instead of learning implicit preferences, RewardAnything follows <span class="font-semibold">explicit natural language principles</span> ‚Äî enabling dynamic adaptation to any evaluation criteria without retraining.
                </p>
                
                <!-- Mini Demo -->
                <div class="bg-white/10 backdrop-blur-sm rounded-xl p-6 max-w-4xl mx-auto">
                    <div class="grid md:grid-cols-2 gap-6 text-left">
                        <div>
                            <div class="text-sm font-semibold text-blue-200 mb-2">üìã Principle A: Brevity Focus</div>
                            <div class="bg-blue-500/20 p-3 rounded-lg text-sm">
                                "Prefer concise, to-the-point responses that directly answer the question without unnecessary details."
                            </div>
                            <div class="mt-2 text-xs text-blue-200">‚Üí Ranks brief, accurate answer highest</div>
                        </div>
                        <div>
                            <div class="text-sm font-semibold text-purple-200 mb-2">üìã Principle B: Detail Focus</div>
                            <div class="bg-purple-500/20 p-3 rounded-lg text-sm">
                                "Prefer comprehensive responses with detailed explanations, examples, and thorough coverage of the topic."
                            </div>
                            <div class="mt-2 text-xs text-purple-200">‚Üí Ranks detailed, educational answer highest</div>
                        </div>
                    </div>
                    <div class="text-center mt-4 text-sm text-white/80">
                        <span class="font-semibold">Same model, same responses, different principles ‚Üí different rankings</span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Problem & Solution Overview -->
<section class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">The Problem with Current Reward Models</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                Traditional reward models learn implicit preferences from fixed datasets, making them rigid and unable to adapt to diverse real-world needs.
            </p>
        </div>

        <!-- Research Figure Container -->
        <div class="paper-figure-container mb-16">
            <div class="max-w-5xl mx-auto">
                <img src="{{ '/assets/images/figure_1_placeholder.jpg' | relative_url }}" 
                     alt="Figure 1: Current post-training optimization paradigm vs RewardAnything approach"
                     class="w-full h-auto rounded-lg shadow-sm">
                <p class="text-sm text-gray-600 text-center mt-4 italic">
                    <strong>Figure 1:</strong> Current post-training optimization requires costly retraining for different preferences. 
                    RewardAnything directly follows natural language principles without retraining.
                </p>
            </div>
        </div>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-12">
            <!-- Current Limitations -->
            <div class="bg-red-50 p-8 rounded-xl">
                <div class="text-red-600 text-2xl mb-4">‚ö†Ô∏è</div>
                <h3 class="text-xl font-bold text-red-900 mb-4">Current Limitations</h3>
                <ul class="space-y-3 text-red-800">
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Limited Adaptability:</strong> Need to retrain for different preference criteria</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Implicit Learning:</strong> Learn biases from spurious correlations in data</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Costly Updates:</strong> Require new preference data collection and retraining</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-red-600 mr-2">‚Ä¢</span>
                        <span><strong>Poor Interpretability:</strong> Difficult to understand decision rationale</span>
                    </li>
                </ul>
            </div>

            <!-- Our Solution -->
            <div class="bg-green-50 p-8 rounded-xl">
                <div class="text-green-600 text-2xl mb-4">‚úÖ</div>
                <h3 class="text-xl font-bold text-green-900 mb-4">RewardAnything Solution</h3>
                <ul class="space-y-3 text-green-800">
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Principle-Following:</strong> Adapt to any explicit natural language criteria</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Zero Retraining:</strong> Dynamic adaptation without model updates</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Transparent Reasoning:</strong> Explicit explanations for decisions</span>
                    </li>
                    <li class="flex items-start">
                        <span class="text-green-600 mr-2">‚Ä¢</span>
                        <span><strong>Bias Mitigation:</strong> Clear principles eliminate spurious correlations</span>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</section>

<!-- Installation & Usage Guide -->
<section id="quickstart" class="py-20 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">üöÄ Quick Start</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                RewardAnything offers three flexible deployment options to fit your workflow, from quick experimentation to production-scale evaluation.
            </p>
        </div>

            <!-- Installation -->
        <div class="mb-16">
            <div class="bg-gray-50 rounded-xl p-8">
                <h3 class="text-xl font-bold text-gray-900 mb-4">üì¶ Installation</h3>
                <div class="bg-gray-900 rounded-lg p-4">
                    <code class="text-green-400 font-mono">pip install rewardanything</code>
                </div>
            </div>
        </div>

        <!-- Three Deployment Methods -->
        <div class="grid md:grid-cols-3 gap-8 mb-16">
            <!-- Method 1: Local Inference -->
            <div class="deployment-card blue bg-gradient-to-br from-blue-50 to-indigo-100 rounded-xl p-6 border border-blue-200" 
                 onclick="selectDeploymentMethod('local')" data-method="local">
                <!-- Recommended Tag -->
                <div class="flex justify-between items-start mb-3">
                    <span class="inline-block bg-blue-500 text-white text-xs px-2 py-1 rounded-full font-medium">
                        Recommended for Beginners
                    </span>
                    <span class="text-2xl">üè†</span>
                </div>
                
                <h3 class="text-xl font-bold text-gray-900 mb-2">Local Inference</h3>
                <p class="text-gray-600 mb-4">Perfect for quick experimentation and research</p>
                
                <!-- Use Case Tags -->
                <div class="flex flex-wrap gap-2 mb-4">
                    <span class="inline-block bg-blue-100 text-blue-800 text-xs px-2 py-1 rounded-md font-medium">Quick Testing</span>
                    <span class="inline-block bg-blue-100 text-blue-800 text-xs px-2 py-1 rounded-md font-medium">Research</span>
                    <span class="inline-block bg-blue-100 text-blue-800 text-xs px-2 py-1 rounded-md font-medium">Offline Use</span>
                </div>
                
                <div class="space-y-3 mb-4">
                    <div>
                        <div class="text-sm font-semibold text-green-700 mb-1">‚úÖ Pros:</div>
                        <ul class="text-xs text-gray-600 space-y-1">
                            <li>‚Ä¢ Simple one-line setup</li>
                            <li>‚Ä¢ No external dependencies</li>
                            <li>‚Ä¢ Full control & offline capable</li>
                        </ul>
                    </div>
                    
                    <div>
                        <div class="text-sm font-semibold text-orange-700 mb-1">‚ö†Ô∏è Cons:</div>
                        <ul class="text-xs text-gray-600 space-y-1">
                            <li>‚Ä¢ Local GPU required (8GB+ VRAM)</li>
                            <li>‚Ä¢ Not ideal for batch processing</li>
                        </ul>
                    </div>
                </div>
                
                <div class="flex justify-center">
                    <div class="text-blue-600 text-sm font-medium bg-blue-100 px-4 py-2 rounded-lg hover:bg-blue-200 transition-colors cursor-pointer">
                        View Guides ‚Üí
                    </div>
                </div>
            </div>

            <!-- Method 2: vLLM Deployment -->
            <div class="deployment-card emerald bg-gradient-to-br from-emerald-50 to-green-100 rounded-xl p-6 border border-emerald-200" 
                 onclick="selectDeploymentMethod('vllm')" data-method="vllm">
                <!-- Recommended Tag -->
                <div class="flex justify-between items-start mb-3">
                    <span class="inline-block bg-emerald-500 text-white text-xs px-2 py-1 rounded-full font-medium">
                        Recommended for Production
                    </span>
                    <span class="text-2xl">üöÄ</span>
                </div>
                
                <h3 class="text-xl font-bold text-gray-900 mb-2">vLLM Deployment</h3>
                <p class="text-gray-600 mb-4">Optimized for high-throughput and production</p>
                
                <!-- Use Case Tags -->
                <div class="flex flex-wrap gap-2 mb-4">
                    <span class="inline-block bg-emerald-100 text-emerald-800 text-xs px-2 py-1 rounded-md font-medium">Production</span>
                    <span class="inline-block bg-emerald-100 text-emerald-800 text-xs px-2 py-1 rounded-md font-medium">RLHF Training</span>
                    <span class="inline-block bg-emerald-100 text-emerald-800 text-xs px-2 py-1 rounded-md font-medium">Batch Processing</span>
                </div>
                
                <div class="space-y-3 mb-4">
                    <div>
                        <div class="text-sm font-semibold text-green-700 mb-1">‚úÖ Pros:</div>
                        <ul class="text-xs text-gray-600 space-y-1">
                            <li>‚Ä¢ Distributed & concurrent inference</li>
                            <li>‚Ä¢ Production-ready scalability</li>
                            <li>‚Ä¢ Optimized memory usage</li>
                        </ul>
                    </div>
                    
                    <div>
                        <div class="text-sm font-semibold text-orange-700 mb-1">‚ö†Ô∏è Cons:</div>
                        <ul class="text-xs text-gray-600 space-y-1">
                            <li>‚Ä¢ vLLM setup required</li>
                            <li>‚Ä¢ More complex configuration</li>
                        </ul>
                    </div>
                </div>
                
                <div class="flex justify-center">
                    <div class="text-emerald-600 text-sm font-medium bg-emerald-100 px-4 py-2 rounded-lg hover:bg-emerald-200 transition-colors cursor-pointer">
                        View Guides ‚Üí
                    </div>
                </div>
            </div>

            <!-- Method 3: Transformers Direct -->
            <div class="deployment-card purple bg-gradient-to-br from-purple-50 to-violet-100 rounded-xl p-6 border border-purple-200" 
                 onclick="selectDeploymentMethod('huggingface')" data-method="huggingface">
                <!-- Recommended Tag -->
                <div class="flex justify-between items-start mb-3">
                    <span class="inline-block bg-purple-500 text-white text-xs px-2 py-1 rounded-full font-medium">
                        Recommended for Customization
                    </span>
                    <span class="text-2xl">üîß</span>
                </div>
                
                <h3 class="text-xl font-bold text-gray-900 mb-2">Transformers Direct</h3>
                <p class="text-gray-600 mb-4">Maximum flexibility for custom workflows</p>
                
                <!-- Use Case Tags -->
                <div class="flex flex-wrap gap-2 mb-4">
                    <span class="inline-block bg-purple-100 text-purple-800 text-xs px-2 py-1 rounded-md font-medium">Custom Logic</span>
                    <span class="inline-block bg-purple-100 text-purple-800 text-xs px-2 py-1 rounded-md font-medium">Research</span>
                    <span class="inline-block bg-purple-100 text-purple-800 text-xs px-2 py-1 rounded-md font-medium">Low-level Control</span>
                </div>
                
                <div class="space-y-3 mb-4">
                    <div>
                        <div class="text-sm font-semibold text-green-700 mb-1">‚úÖ Pros:</div>
                        <ul class="text-xs text-gray-600 space-y-1">
                            <li>‚Ä¢ Full model control & access</li>
                            <li>‚Ä¢ Custom processing pipelines</li>
                            <li>‚Ä¢ HuggingFace ecosystem</li>
                        </ul>
                    </div>
                    
                    <div>
                        <div class="text-sm font-semibold text-orange-700 mb-1">‚ö†Ô∏è Cons:</div>
                        <ul class="text-xs text-gray-600 space-y-1">
                            <li>‚Ä¢ Manual output parsing</li>
                            <li>‚Ä¢ More boilerplate code</li>
                        </ul>
                    </div>
                </div>
                
                <div class="flex justify-center">
                    <div class="text-purple-600 text-sm font-medium bg-purple-100 px-4 py-2 rounded-lg hover:bg-purple-200 transition-colors cursor-pointer">
                        View Guides ‚Üí
                    </div>
                </div>
            </div>
        </div>

        <!-- Code Examples -->
        <div class="bg-gray-50 rounded-xl p-8">
            <!-- Local Inference Tab -->
            <div id="local-tab" class="tab-content">
                <div class="flex items-center gap-3 mb-6">
                    <span class="text-2xl">üè†</span>
                    <div>
                        <h4 class="text-lg font-bold text-gray-900">Local Inference</h4>
                        <p class="text-sm text-gray-600">Simple setup for quick testing and research</p>
                    </div>
                </div>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python">import rewardanything

# Load model locally (downloads automatically on first use)
reward_model = rewardanything.RewardModel("zhuohaoyu/RewardAnything-8B-v1")

# Define your evaluation principle
principle = "Judge responses based on helpfulness, accuracy, and clarity. Prefer concise but complete answers."

# Prepare responses to evaluate
prompt = "How do I learn Python programming?"
responses = {
    "assistant_a": "Start with Python.org tutorials, practice daily coding, and build small projects.",
    "assistant_b": "Python is a programming language. It's used for many things.",
    "assistant_c": "Begin with Python.org's official tutorial, practice coding daily, join communities like r/learnpython, and work on projects that interest you."
}

# Evaluate and get results
result = reward_model.judge(
    principle=principle,
    prompt=prompt,
    responses=responses
)

# Access results
print(f"Scores: {result.scores}")
print(f"Ranking: {result.ranking}")
print(f"Explanation: {result.explanation}")</code></pre>
                </div>
            </div>

            <!-- vLLM Deployment Tab -->
            <div id="vllm-tab" class="tab-content hidden">
                <div class="flex items-center gap-3 mb-6">
                    <span class="text-2xl">üöÄ</span>
                    <div>
                        <h4 class="text-lg font-bold text-gray-900">vLLM Deployment</h4>
                        <p class="text-sm text-gray-600">Production-ready setup for high-throughput evaluation</p>
                    </div>
                </div>
                <div class="space-y-6">
                    <div>
                        <h5 class="font-semibold text-gray-800 mb-2">Step 1: Setup vLLM Server</h5>
                        <div class="rounded-lg overflow-hidden">
                            <pre><code class="language-bash"># Start vLLM server with RewardAnything model
vllm serve zhuohaoyu/RewardAnything-8B-v1 --host 0.0.0.0 --port 8000</code></pre>
                        </div>
                    </div>

                    <div>
                        <h5 class="font-semibold text-gray-800 mb-2">Step 2: Start RewardAnything Server</h5>
                        <div class="rounded-lg overflow-hidden">
                            <pre><code class="language-bash"># Start the RewardAnything API server
rewardanything serve -c config.json --port 8001</code></pre>
                        </div>
                    </div>

                    <div>
                        <h5 class="font-semibold text-gray-800 mb-2">Step 3: Use in Your Code</h5>
                        <div class="rounded-lg overflow-hidden">
                            <pre><code class="language-python">import rewardanything

# Connect to the RewardAnything server
client = rewardanything.Client("http://localhost:8001")

# Process batch requests efficiently
requests = [
    {
        "principle": "Prefer clear, concise and helpful responses...",
        "prompt": "How to learn programming?",
        "responses": {
            "assistant_a": "Start with Python, practice daily, build projects.",
            "assistant_b": "Read books and hope for the best.",
            "assistant_c": "Start with Python.org's tutorial, practice daily..."
        }
    },
    # ... more requests
]

results = client.judge_batch(requests)
for result in results:
    print(f"Winner: {result.ranking[0]}")</code></pre>
                        </div>
                    </div>
                </div>
            </div>

            <!-- HuggingFace Direct Tab -->
            <div id="huggingface-tab" class="tab-content hidden">
                <div class="flex items-center gap-3 mb-6">
                    <span class="text-2xl">üîß</span>
                    <div>
                        <h4 class="text-lg font-bold text-gray-900">Direct Transformers Integration</h4>
                        <p class="text-sm text-gray-600">Maximum flexibility for custom workflows and advanced use cases</p>
                    </div>
                </div>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python">from transformers import AutoTokenizer, AutoModelForCausalLM
from rewardanything.processing import prepare_chat_messages, parse_rewardanything_output
import torch

# Load model and tokenizer directly
model = AutoModelForCausalLM.from_pretrained(
    "zhuohaoyu/RewardAnything-8B-v1",
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained("zhuohaoyu/RewardAnything-8B-v1")

# Prepare evaluation data
principle = "Judge responses based on helpfulness and accuracy"
prompt = "What is the capital of France?"
responses = {
    "model_a": "Paris is the capital of France.",
    "model_b": "I think it might be Lyon or Paris."
}

# Prepare chat messages (handles masking automatically)
messages, masked2real = prepare_chat_messages(principle, prompt, responses)

# Format with chat template
formatted_input = tokenizer.apply_chat_template(
    messages, tokenize=False, add_generation_prompt=True
)

# Generate response
inputs = tokenizer(formatted_input, return_tensors="pt").to(model.device)
with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=4096,
        temperature=0.1,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id
    )

# Parse structured results (handles JSON parsing robustly)
output_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
result = parse_rewardanything_output(output_text, masked2real)

print(f"Parsed scores: {result.scores}")
print(f"Ranking: {result.ranking}")</code></pre>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Advanced Usage -->
<section class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">üî¨ Advanced Usage</h2>
            <p class="text-xl text-gray-600 max-w-4xl mx-auto">
                Unlock the full potential of RewardAnything with sophisticated principles and RLHF integration.
            </p>
        </div>

        <div class="grid md:grid-cols-2 gap-8">
            <!-- Custom Principles -->
            <div class="bg-white rounded-xl p-8 shadow-sm border border-gray-200">
                <h3 class="text-xl font-bold text-gray-900 mb-4">üéØ Custom Principles</h3>
                <p class="text-gray-600 mb-4">RewardAnything excels with sophisticated, multi-criteria principles:</p>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python">complex_principle = """
Evaluate responses using these criteria:
1. **Technical Accuracy** (40%): Factual correctness
2. **Clarity** (30%): Clear explanations  
3. **Practical Value** (20%): Actionable advice
4. **Safety** (10%): No harmful content

Priority: safety > accuracy > clarity > practical value.
"""

result = reward_model.judge(complex_principle, prompt, responses)</code></pre>
                </div>
            </div>

            <!-- RLHF Integration -->
            <div class="bg-white rounded-xl p-8 shadow-sm border border-gray-200">
                <h3 class="text-xl font-bold text-gray-900 mb-4">üîÑ RLHF Integration</h3>
                <p class="text-gray-600 mb-4">Seamlessly integrate with your RLHF training pipelines:</p>
                <div class="rounded-lg overflow-hidden">
                    <pre><code class="language-python"># Example: Use in PPO training loop
def reward_function(principle, prompt, response):
    result = reward_model.judge(
        principle=principle,
        prompt=prompt,
        responses={"generated": response, "reference": "baseline"}
    )
    return result.scores["generated"]

# Use in your RLHF training
rewards = [reward_function(principle, prompt, resp) 
          for resp in generated_responses]</code></pre>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Performance Results -->
<section class="py-20 bg-gradient-to-br from-blue-50 to-indigo-100">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">State-of-the-Art Performance</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                RewardAnything achieves excellent performance on both traditional benchmarks and our new principle-following evaluation
            </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
            <!-- RM-Bench Results -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <div class="text-center mb-6">
                    <div class="text-3xl font-bold text-blue-600 mb-2">89.2%</div>
                    <div class="text-lg font-semibold text-gray-900">RM-Bench Accuracy</div>
                    <div class="text-sm text-gray-600">State-of-the-art on challenging "hard" settings</div>
                </div>
                <div class="space-y-3 text-sm">
                    <div class="flex justify-between">
                        <span class="text-gray-600">Math:</span>
                        <span class="font-semibold">89.1%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Code:</span>
                        <span class="font-semibold">89.1%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Safety:</span>
                        <span class="font-semibold">89.6%</span>
                    </div>
                </div>
            </div>

            <!-- RABench Results -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <div class="text-center mb-6">
                    <div class="text-3xl font-bold text-green-600 mb-2">80.5%</div>
                    <div class="text-lg font-semibold text-gray-900">RABench Accuracy</div>
                    <div class="text-sm text-gray-600">Novel benchmark for principle-following</div>
                </div>
                <div class="space-y-3 text-sm">
                    <div class="flex justify-between">
                        <span class="text-gray-600">Content:</span>
                        <span class="font-semibold">82.6%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Logic:</span>
                        <span class="font-semibold">80.7%</span>
                    </div>
                    <div class="flex justify-between">
                        <span class="text-gray-600">Style:</span>
                        <span class="font-semibold">80.5%</span>
                    </div>
                </div>
            </div>

            <!-- Key Advantages -->
            <div class="bg-white p-8 rounded-xl shadow-sm">
                <div class="text-center mb-6">
                    <div class="text-3xl font-bold text-purple-600 mb-2">Zero</div>
                    <div class="text-lg font-semibold text-gray-900">Retraining Required</div>
                    <div class="text-sm text-gray-600">Adapt to new principles instantly</div>
                </div>
                <div class="space-y-3 text-sm">
                    <div class="flex items-center">
                        <div class="w-2 h-2 bg-green-500 rounded-full mr-2"></div>
                        <span>200+ principle categories</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-2 h-2 bg-green-500 rounded-full mr-2"></div>
                        <span>Listwise evaluation</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-2 h-2 bg-green-500 rounded-full mr-2"></div>
                        <span>Transparent reasoning</span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Key Features -->
<section class="py-20 bg-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">Key Innovations</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                RewardAnything introduces novel techniques for principle-following reward modeling
            </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-2 gap-12">
            <div class="space-y-8">
                <div class="space-y-4">
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Group Relative Policy Optimization (GRPO)</h4>
                            <p class="text-gray-600">Advanced RL training that learns relative preferences within response groups</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Listwise Evaluation</h4>
                            <p class="text-gray-600">Efficient ranking of multiple responses in a single forward pass</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-blue-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Inference-Time Reasoning</h4>
                            <p class="text-gray-600">Explicit reasoning process for transparent decision making</p>
                        </div>
                    </div>
                </div>
                <div class="space-y-4">
                    <div class="flex items-start">
                        <div class="bg-green-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-green-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Multi-LLM Consensus</h4>
                            <p class="text-gray-600">Ground truth from 4 state-of-the-art LLMs with algorithmic consensus</p>
                        </div>
                    </div>
                    <div class="flex items-start">
                        <div class="bg-green-100 p-2 rounded-lg mr-4">
                            <svg class="w-5 h-5 text-green-600" fill="currentColor" viewBox="0 0 20 20">
                                <path d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                            </svg>
                        </div>
                        <div>
                            <h4 class="font-semibold text-gray-900">Human Verification</h4>
                            <p class="text-gray-600">89% agreement rate with Œ∫=0.57 for reliable evaluation standards</p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- RABench Description -->
            <div class="bg-gray-50 p-8 rounded-xl">
                <h3 class="text-xl font-bold text-gray-900 mb-4">RABench: Novel Evaluation Framework</h3>
                <p class="text-gray-700 mb-6">
                    We introduce RABench, a comprehensive benchmark specifically designed to evaluate reward models' 
                    ability to follow explicit natural language principles across diverse domains and criteria.
                </p>
                <div class="space-y-4">
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-blue-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>1,002 validated rankings</strong> across 50 principles</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-green-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>5 principle categories:</strong> Content, Logic, Style, Tone, Structure</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-purple-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>Multiple domains:</strong> Chat, Code, Safety, Math</span>
                    </div>
                    <div class="flex items-center">
                        <div class="w-3 h-3 bg-orange-500 rounded-full mr-3"></div>
                        <span class="text-gray-700"><strong>Human-verified quality</strong> with high inter-annotator agreement</span>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Documentation -->
<section id="documentation" class="py-20 bg-gray-50">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-16">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-4">Documentation & Resources</h2>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">
                Everything you need to understand and use RewardAnything for your research and applications
            </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6">
            <a href="{{ site.paper_url | default: '#' }}" class="block bg-blue-50 p-6 rounded-xl hover:bg-blue-100 transition-colors">
                <div class="text-2xl mb-3">üìÑ</div>
                <h3 class="font-semibold text-blue-900 mb-2">Research Paper</h3>
                <p class="text-sm text-blue-700">Complete methodology, experiments, and theoretical foundations</p>
            </a>

            <a href="#" class="block bg-green-50 p-6 rounded-xl hover:bg-green-100 transition-colors">
                <div class="text-2xl mb-3">üöÄ</div>
                <h3 class="font-semibold text-green-900 mb-2">API Documentation</h3>
                <p class="text-sm text-green-700">Comprehensive guide to using RewardAnything in your code</p>
            </a>

            <a href="#" class="block bg-purple-50 p-6 rounded-xl hover:bg-purple-100 transition-colors">
                <div class="text-2xl mb-3">üìä</div>
                <h3 class="font-semibold text-purple-900 mb-2">RABench Dataset</h3>
                <p class="text-sm text-purple-700">Benchmark dataset for evaluating principle-following capabilities</p>
            </a>

            <a href="{{ site.huggingface_url | default: '#' }}" class="block bg-orange-50 p-6 rounded-xl hover:bg-orange-100 transition-colors">
                <div class="text-2xl mb-3">ü§ó</div>
                <h3 class="font-semibold text-orange-900 mb-2">Model Weights</h3>
                <p class="text-sm text-orange-700">Pre-trained models ready for inference and fine-tuning</p>
            </a>
        </div>
    </div>
</section>

<!-- Citation -->
<section class="py-20 bg-gray-900 text-white">
    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div class="text-center mb-12">
            <h2 class="text-3xl md:text-4xl font-bold mb-4">Citation</h2>
            <p class="text-xl text-gray-300 max-w-3xl mx-auto">
                If you use RewardAnything in your research, please cite our paper
            </p>
        </div>

        <div class="max-w-4xl mx-auto">
            <div class="bg-gray-800 p-6 rounded-xl">
                <pre><code class="language-latex">@article{yu2024rewardanything,
  title={RewardAnything: Generalizable Principle-Following Reward Models},
  author={Yu, Zhuohao and Zeng, Jiali and Gu, Weizheng and Wang, Yidong and 
          Wang, Jindong and Meng, Fandong and Zhou, Jie and Zhang, Yue and 
          Zhang, Shikun and Ye, Wei},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2025}
}</code></pre>
            </div>
        </div>
    </div>
</section>

<style>
/* Special container for paper figures with neutral background */
.paper-figure-container {
    background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
    padding: 2rem;
    border-radius: 1rem;
    border: 1px solid #e2e8f0;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05);
}

.paper-figure-container img {
    background: white;
    padding: 1rem;
    border-radius: 0.5rem;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

.tab-button {
    @apply px-4 py-2 rounded-lg text-sm font-medium transition-colors;
    @apply bg-gray-200 text-gray-700 hover:bg-gray-300;
}

.tab-button.active {
    @apply bg-blue-600 text-white hover:bg-blue-700;
}

.tab-content {
    @apply transition-all duration-300;
}
</style> 

<script>
function selectDeploymentMethod(method) {
    // Remove selected state from all cards
    document.querySelectorAll('.deployment-card').forEach(card => {
        card.classList.remove('selected');
    });
    
    // Add selected state to clicked card
    document.querySelector(`[data-method="${method}"]`).classList.add('selected');
    
    // Show corresponding tab
    showTab(method);
}

function showTab(tabName) {
    // Hide all tab contents
    document.querySelectorAll('.tab-content').forEach(tab => {
        tab.classList.add('hidden');
    });
    
    // Show selected tab content
    document.getElementById(tabName + '-tab').classList.remove('hidden');
    
    // Trigger Prism.js to highlight code
    if (typeof Prism !== 'undefined') {
        Prism.highlightAll();
    }
}

// Initialize on page load
document.addEventListener('DOMContentLoaded', function() {
    // Select first deployment method by default WITHOUT scrolling
    document.querySelector(`[data-method="local"]`).classList.add('selected');
    showTab('local');
    
    // Highlight all code blocks
    if (typeof Prism !== 'undefined') {
        Prism.highlightAll();
    }
});
</script> 